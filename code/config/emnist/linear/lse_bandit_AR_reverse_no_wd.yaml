template: true
optimizer: 'SGD'
dataset: 'emnist_raw_linear/${TAU}_${UL}'
num_sample: 1
lr: 0.001
epochs: 300
batch_size: 256
batch_log_interval: 50
train_limit: 500_000
lse_lamda: 2.0
lamda: 0
experiment:
  name: 'full_lse_bandit_feedback_AR_Reverse'
  n_exp: 3
  n_trials: 8
  feedback: 'bandit'
  regularizers:
    AlphaRenyi:
      alpha: [0.1, 10]
      beta: [0.001, 10]
      type: 2