template: true
optimizer: 'SGD'
dataset: 'fmnist_old/${TAU}_${UL}'
num_sample: 1
weight_decay: 
- 0.000001
- 0.000001
lr: 0.001
epochs: 300
batch_size: 256
batch_log_interval: 50
train_limit: 500_000
exs_alpha: 1
lamda: 0
experiment: 
  name: 'full_exponential_smoothing_bandit_feedback'
  n_exp: 3
  n_trials: 1
  feedback: 'bandit'
  regularizers: null